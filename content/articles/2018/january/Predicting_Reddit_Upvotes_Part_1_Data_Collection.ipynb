{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At University of Maryland, Baltimore County's annual hackathon, 5 guys came together to produce an single page web app.  The app was named Calzone.  Calzone's purpose was to predict the number of upvotes a Redditt post would receive based solely on the title.  \n",
    "\n",
    "This blog article is a 12 part series that will describe the data collection, feature extraction, and regression analysis(prediction) used to build Calzone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1:  Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to collect a year's worth of posts from the r/politics subreddit.  We used the PRAW [package](https://github.com/praw-dev/praw) to access Reddit's api.  To submit an api request, you first must request OAuth credentials from Reddit.  See [here](https://github.com/reddit/reddit/wiki/OAuth2) for instructions on how to do such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our credentials let's get going.  The full code is below. We will begin by initializing a reddit instance.  We next select a subreddit and retrieve the submissions for the past year.  Selection of posts over a given time frame requires that a timestamp be specified.  The 'get_timestamps' function allows you to input the beginning and end dates (format 01/01/2001).  The submissions variable is a generator object and contains all the data.  We looped through the submissions and obtained the id, title, number of votes, url, and creation date for each post. Finally, the collected data is saved to a pandas dataframe object then written to a csv file.  The follow-up article will deal with data cleanup and exploratory analysis.  See you around! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import calendar\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# To specifying date ranges in PRAW require timestamps\n",
    "def get_timestamps(time1,time2):\n",
    "    ''' Convert date range into timestamps\n",
    "    \n",
    "    time1(str):  start date formated as 01/01/2001\n",
    "    time2(str):  end date formated as 01/01/2001\n",
    "    \n",
    "    returns(str) start and end timestamps\n",
    "    '''\n",
    "    month1, day1, year1 = time1.split('/')\n",
    "    month2, day2, year2 = time2.split('/')\n",
    "    dt1 = datetime(int(year1), int(month1), int(day1))\n",
    "    dt2 = datetime(int(year2), int(month2), int(day2))\n",
    "    t1 = calendar.timegm(dt1.timetuple())\n",
    "    t2 = calendar.timegm(dt2.timetuple())\n",
    "    return t1,t2\n",
    "\n",
    "\n",
    "# Step 1: Intialize reddit connection \n",
    "reddit = praw.Reddit(client_id='CLIENT_ID', client_secret=\"CLIENT_SECRET\",\n",
    "                     password='PASSWORD', user_agent='USERAGENT',\n",
    "                     username='USERNAME')\n",
    "# Step 2: define subreddit to capture\n",
    "subreddit = reddit.subreddit('politics')\n",
    "\n",
    "\n",
    "# Step 3: Select time frame and acquire posts from specified subreddit\n",
    "t1,t2 = get_timestamps('01/01/2017', '12/31/2017')\n",
    "submissions = subreddit.submissions(t1,t2)\n",
    "\n",
    "# Step 4: Extract pertinent information from posts\n",
    "data = [[data.id, data.subreddit_name_prefixed,\n",
    "         data.title, data.ups, data.url, data.created_utc] for data in submissions]\n",
    "\n",
    "# Step 5: Place data in pandas dataframe\n",
    "df = pd.DataFrame(data,\n",
    "                  columns=['id', 'subreddit', 'title', 'ups', 'url', 'created_utc'])\n",
    "# Step 6: Save to CSV file\n",
    "df.to_csv('data_blog.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
